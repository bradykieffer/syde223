{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Algorithm Analysis\n",
    "------------------------------------------------\n",
    "Brady Kieffer - <bwkieffe@edu.uwaterloo.ca>\n",
    "\n",
    "All of the tutorial related code / other documents will be on d2l as well as [this](https://github.com/bradykieffer/syde223) git repo.\n",
    "\n",
    "This tutorial will cover concepts from chapter 3 of the textbook. I like using Jupyter notebooks as a way to try out code. If you want to learn more about installing Jupyter on your own machine just go [here](http://jupyter.org/).\n",
    "\n",
    "## Introduction\n",
    "-------------------\n",
    "\n",
    "![algorithm-analysis](https://imgs.xkcd.com/comics/algorithms.png)\n",
    "\n",
    "- When we want to classify either algorithms or datastructures as \"good\" we need some method of comparing them\n",
    "- Typically, we analyze the running time of algorithms.\n",
    "- We can also look at memory usage\n",
    "- Focusing on running time means we get to use math!\n",
    "\n",
    "However, we can also illustrate algorithm complexity using real examples. Let's first look at a basic example for measuring performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for graphing used later\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')  # This is almost never a good idea\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "def my_algorithm(should_print=True):\n",
    "    if should_print:\n",
    "        print('This is a contrived example.')\n",
    "    time.sleep(0.1)  # Sleep for 0.1ms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long will my_algorithm take?\n",
    "start_time = time.time()\n",
    "my_algorithm()\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print(f'It took {elapsed:0.2f}ms to run my_algorithm.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to test this for multiple runs? Would need to record the runtime for each run, average them, report the standard deviation etc.\n",
    "\n",
    "Or we use a utility in jupyter `%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit my_algorithm(should_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even test out blocks of code using `%%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "n = 0\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sort of analysis is known as **experimental analysis**. \n",
    "\n",
    "\n",
    "It would be much more beneficial to come up with a series metrics to measure general algorithmic complexity. We need to develop measures that will allow us to do the following: \n",
    "\n",
    "1. Compare two algorithms without worrying about hardware / software implementation differences\n",
    "2. Allow us to perform evaluation without actually implementing the algorithm\n",
    "3. Take into account all possible inputs\n",
    "\n",
    "While experimental analysis may be difficult, in this tutorial we will look at examples of different algorithm runtimes using utilities built into Jupyter notebooks.\n",
    "\n",
    "## Primitive Operations\n",
    "\n",
    "The textbook begins this process by first looking at **primitive operations**. A primitive operation is one in which the runtime of the operation effectively remains constant. There are a plethora of specific examples of primitive operations, literally a list in the text (pg 113). The running time of an algorithm will be directly proportional to the number of primitive operations it has.\n",
    "\n",
    "## Measuring Operations as a Function of Input Size\n",
    "\n",
    "To capture the growth of an algorithm's running time, we can assign a function $f(n)$ to the size of the input (number of primitive operations). We will then analyze the **worst-case** running time for that algorithm given a bounding function for $f(n)$. \n",
    "\n",
    "What does this all mean in practice? We will look at some common functions and how they scale as a function of input size. Specifically, the textbook looks at the following functions:\n",
    "\n",
    "- The constant function $f(n) = c$\n",
    "- The logarithm function (base 2) $f(n) = log(n)$\n",
    "- The linear function $f(n) = n$\n",
    "- The N-Log-N function $f(n) = nlog(n)$\n",
    "- The quadratic function $f(n) = n^2$\n",
    "- The exponential function $f(n) = b^n$\n",
    "- Other polynomial functions\n",
    "\n",
    "But how do these actually scale with respect to one another? Let's use the provided functions to analyze this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's gather a list of the runtimes for an algorithm\n",
    "import numpy as np\n",
    "\n",
    "n_inputs = list(range(3, 100))\n",
    "\n",
    "runtimes = {\n",
    "    'constant': [1 for n in n_inputs],\n",
    "    'logarithmic': [np.log2(n) for n in n_inputs],\n",
    "    'linear': [n for n in n_inputs],\n",
    "    'n-log(n)': [n * np.log2(n) for n in n_inputs],\n",
    "    'quadratic': [n * n for n in n_inputs],\n",
    "    'exponential': [1.1 ** n for n in n_inputs]\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for label, runtime in runtimes.items():\n",
    "    plt.loglog(n_inputs, runtime, label=label)\n",
    "\n",
    "# Plot the results\n",
    "plt.legend()\n",
    "plt.ylabel('log of Runtime')\n",
    "plt.xlabel('log of # Inputs')\n",
    "plt.title('The Runtime of Each Algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, different functions will have wildly different runtimes.\n",
    "\n",
    "All of this is great, but how does it connect with actual algorithms? In reality, we only need to analyze the worst-case runtime of an algorithm. This means that if we can come up with a function that models the runtime of our algorithm with respect to the number of inputs, we should be able to realize the worst-case runtime. \n",
    "\n",
    "## Asymptotic Analysis and \"Big-Oh\" Notation\n",
    "\n",
    "This is all great, but we should investigate examples of different scaling in Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O(1) \n",
    "This is relatively simple to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant(n):\n",
    "    a = n\n",
    "    b = n - 1\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O(n) \n",
    "Occurs whenever we loop over something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O($n^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O(log(n))\n",
    "\n",
    "Not as easy to immediately see but this will start to appear later in the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logarithmic(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O(nlog(n))\n",
    "\n",
    "Even weirder than O(log(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_example(n):\n",
    "    \"\"\" Found this gem on Quora \"\"\"\n",
    "    for _ in range(1, n + 1):\n",
    "        time.sleep(np.log(n))  # Sleep for log(n) seconds\n",
    "        \n",
    "bad_example(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_log(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Real' Examples\n",
    "To find this worst-case runtime, we first get a function noting the number of operations performed relative to the number of inputs and then use a bounding function to denote the expected runtime. For example, consider the following algorithm which will find the smallest value in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runtime(algorithm, data, times=2):\n",
    "    runtimes = []\n",
    "    for _ in range(times):\n",
    "        start = time.time()\n",
    "        algorithm(data)\n",
    "        end = time.time()\n",
    "        runtimes.append(end - start)\n",
    "\n",
    "    return np.mean(runtimes), np.std(runtimes)\n",
    "\n",
    "def plot_runtimes(runtimes, n_inputs):\n",
    "    mean_times = runtimes[:, 0]\n",
    "    std_times = runtimes[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.errorbar(n_inputs, y=mean_times, yerr=std_times)\n",
    "    plt.ylabel('Runtime')\n",
    "    plt.xlabel('# Inputs')\n",
    "    plt.title('The Runtime of find_min')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(data):\n",
    "    min_ = data[0]        # This is a constant operation, O(1)\n",
    "    for value in data:    # A single loop is O(n)\n",
    "        if value < min_:  # This comparison is O(1)\n",
    "            min_ = value  # Assignments are O(1)\n",
    "    return min_           # The return operation is O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the runtime of this algorithm? We could perform experimental analysis to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = list(range(1, 1000))\n",
    "runtimes = np.array([get_runtime(find_min, np.random.randn(n), times=10) for n in n_inputs])\n",
    "\n",
    "plot_runtimes(runtimes, n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *appears* to be linear, but the measurements are subject to noise and the implementation details of the computer running this code. Instead we could note that this algorithm actually iterates over every element of the array checking if it is less than the current minimum and because we do this, the algorithm scales linearly with the number of inputs. When an algorithm scales linearly with the number of inputs, we can effectively bound it using a linear function, we then say that the algorithm has linear time complexity or is $O(n)$ (\"Big-Oh-n\").\n",
    "\n",
    "Let's look at another example which will find the minimum value within a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_matrix(data):\n",
    "    min_ = data[0, 0]\n",
    "    for row in data:\n",
    "        for value in row:\n",
    "            if value < min_:\n",
    "                min_ = value\n",
    "                \n",
    "    return min_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this algorithm scale with input size? Assuming an $n \\times n$ matrix, we note that each cell within the matrix must be checked, thus the expected runtime would be quadratic or $O(n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = list(range(1, 500))\n",
    "runtimes = np.array([get_runtime(find_min_matrix, np.random.randn(n, n), times=5) for n in n_inputs])\n",
    "\n",
    "plot_runtimes(runtimes, n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at one more algorithm which will take a list, add one to each element, and then return the minimum of the list using the `find_min` function previously defined. What is the runtime of this algorithm? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_algorithm(data):\n",
    "    result = [d + 1 for d in data]  # O(n)\n",
    "    result = find_min(result)       # O(n)\n",
    "    return result                   # O(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = list(range(1, 500))\n",
    "runtimes = np.array([get_runtime(my_algorithm, np.random.randn(n), times=10) for n in n_inputs])\n",
    "plot_runtimes(runtimes, n_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Tutorial 'Quiz'\n",
    "It's [here](https://create.kahoot.it/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
